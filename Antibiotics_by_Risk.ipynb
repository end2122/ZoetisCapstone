{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "path_master = r'C:/Users/endwy/Documents/Columbia MSBA/Spring 2019/E4524 - Analytics in Practice/Data/Csv/'\n",
    "file_names = list()\n",
    "for path, subdirs, files in os.walk(path_master):\n",
    "    for filename in files:\n",
    "        file_names.append(filename)\n",
    "df_final = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to read in CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time(df_ABR1):\n",
    "    \"\"\"Add Month and Year column based on read-in file name\"\"\"\n",
    "    mon=re.search(r'\\w+', file_name)\n",
    "    df_ABR1['Month']= file_name[mon.start():mon.end()]\n",
    "    y=re.search(r'\\d+', file_name)\n",
    "    df_ABR1['Year'] = file_name[y.start():y.end()]\n",
    "    \n",
    "def type1(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 columns, missing 7,9, concatenate Mortalities column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','8','10'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '8':'$/Hd/Rx','10':'Treatment $'}, inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type2(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 6,8\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                              usecols=['0','1','2','3','4','5','7','9'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                            '5':'Case Fatality Rate(%)', '7':'$/Hd/Rx', '9':'Treatment $',}, \n",
    "                       inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type3(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"base case\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                          skiprows=[0], \n",
    "                          usecols=['Unnamed: 1', 'Treated', 'Repulls', 'Mortalities', 'Treatment Success',\n",
    "                                   'Case Fatality Rate','$/Hd/Rx', 'Treatment $'])\n",
    "    df_ABR1.rename(columns={'Unnamed: 1': 'Drug', 'Treatment Success':'Treatment Success(%)',\n",
    "                        'Case Fatality Rate':'Case Fatality Rate(%)'}, inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type4(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 7,9, concatenate Treatment column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','8','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'RepullsB', '4':'Mortalities', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '8':'$/Hd/Rx',\n",
    "                        '10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Treatment $'] = (df_ABR1.iloc[i].loc['Treatment $'])+(df_ABR1.iloc[i].loc['Treatment $B'])\n",
    "    del df_ABR1['Treatment $B']\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Repulls'] = (df_ABR1.iloc[i].loc['Repulls'])+(df_ABR1.iloc[i].loc['RepullsB'])\n",
    "    del df_ABR1['RepullsB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type5(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 column, missing 6,8, concatenate Treatment column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','7','9','10'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                        '5':'Case Fatality Rate(%)', '7':'$/Hd/Rx', \n",
    "                        '9':'Treatment $','10':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Treatment $'] = (df_ABR1.iloc[i].loc['Treatment $'])+(df_ABR1.iloc[i].loc['Treatment $B'])\n",
    "    del df_ABR1['Treatment $B']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type6(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 column, concatenate Treatment column\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','3','4','5','6','7','8','9','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '3':'Repulls', '4':'Mortalities','5':'MortalitiesB','6':'Treatment Success(%)', \n",
    "                        '7':'Case Fatality Rate(%)', '8':'$/Hd/Rx', '9':'$/Hd/RxB',\n",
    "                        '10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "        df_ABR1.iloc[i].loc['$/Hd/Rx'] = (df_ABR1.iloc[i].loc['$/Hd/Rx'])+(df_ABR1.iloc[i].loc['$/Hd/RxB'])\n",
    "        df_ABR1.iloc[i].loc['Treatment $'] = (df_ABR1.iloc[i].loc['Treatment $'])+(df_ABR1.iloc[i].loc['Treatment $B'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    del df_ABR1['$/Hd/RxB']\n",
    "    del df_ABR1['Treatment $B']\n",
    "    df_ABR1['Treated']=df_ABR1['Treated'].apply(lambda x: x.replace(' ',''))\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type7(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 8,10\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','4','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '4':'Mortalities', '6':'Treatment Success(%)', \n",
    "                        '7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type8(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 columns, missing 8,9, concatenate Mortalities column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','7','10'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '7':'$/Hd/Rx','10':'Treatment $'},\n",
    "                   inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type9(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"13 columns, missing 10,12\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','5','6','8','9','11','13'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated','2':'Repulls','3':'RepullsB','5':'Mortalities','6':'MortalitiesB',\n",
    "                            '8':'Treatment Success(%)','9':'Case Fatality Rate(%)','11':'$/Hd/Rx','13':'Treatment $'},\n",
    "                   inplace=True)\n",
    "    # Concatenate Repulls & Mortalities columns\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "        df_ABR1.iloc[i].loc['Repulls'] = (df_ABR1.iloc[i].loc['Repulls'])+(df_ABR1.iloc[i].loc['RepullssB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    del df_ABR1['RepullsB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type10(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 8, concatenate Mortalities column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','7','8','10'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '7':'$/Hd/Rx','10':'Treatment $'}, inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type11(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 3,8,10 merge 4,5\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','4','5','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '4':'Mortalities', '5':'MortalitiesB',\n",
    "                            '6':'Treatment Success(%)', '7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "     # Concatenate mortalities column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type12(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 8,10, merge 2,3 and 4,5\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'RepullsB','4':'Mortalities','5':'MortalitiesB',\n",
    "                            '6':'Treatment Success(%)','7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "    # Concatenate Repulls & Mortalities columns\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "        df_ABR1.iloc[i].loc['Repulls'] = (df_ABR1.iloc[i].loc['Repulls'])+(df_ABR1.iloc[i].loc['RepullssB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    del df_ABR1['RepullsB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use functions to clean each month's CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JANUARY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'January\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5' or file_num == '8'or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7'or file_num == '9':\n",
    "                type2(path_master,title,file_num)    \n",
    "                \n",
    "# FEBRUARY 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'February\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5'or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4'or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '7'or file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        elif file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '5':\n",
    "                type8(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '8':\n",
    "                type7(path_master,title,file_num)\n",
    "        \n",
    "# MARCH 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'March\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type7(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '5'or file_num == '6'or file_num == '7'or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type9(path_master,title,file_num)\n",
    "    \n",
    "# APRIL 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'April\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '3' or file_num == '5' or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '7':\n",
    "                type6(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        elif file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num=='4' or file_num=='6' or file_num=='7' or file_num=='10':\n",
    "                type1(path_master,title,file_num)  \n",
    "            elif file_num == '3' or file_num=='5' or file_num=='9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '8':\n",
    "                type7(path_master,title,file_num)\n",
    "                \n",
    "# MAY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'May\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '5' or file_num == '6'or file_num == '7'or file_num == '8'or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "                \n",
    "# JUNE 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'June\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type7(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '4' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '5' or file_num == '6' or file_num == '7'or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type5(path_master,title,file_num)\n",
    "                \n",
    "# JULY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'June\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '5' or file_num == '6' or file_num == '7' or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "                \n",
    "# AUGUST 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'August\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '7' or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '5' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type10(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type11(path_master,title,file_num)\n",
    "                \n",
    "# SEPTEMBER 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'September\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '3' or file_num == '5' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCTOBER 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'September\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type12(path_master,title,file_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out df_ABR\n",
    "import csv\n",
    "\n",
    "# writer = csv.writer(open(path_master+\"/OutputCSV.csv\", 'wb'))\n",
    "df_ABR.to_csv(path_master+\"/df_ABR.csv\")\n",
    "# for row in df_ABR:\n",
    "#     writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To test which function 'type' to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Moderate Risk</td>\n",
       "      <td>52,113</td>\n",
       "      <td>6,533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>,206</td>\n",
       "      <td>87.46%</td>\n",
       "      <td>6.15%</td>\n",
       "      <td>$</td>\n",
       "      <td>20.96</td>\n",
       "      <td>$</td>\n",
       "      <td>1,092,142.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>300 PRO LA</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A180</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A180 As 2nd Rx</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adspec</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Advocin</td>\n",
       "      <td>918</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145</td>\n",
       "      <td>95.32%</td>\n",
       "      <td>15.80%</td>\n",
       "      <td>$</td>\n",
       "      <td>35.27</td>\n",
       "      <td>$</td>\n",
       "      <td>32,376.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Advocin As 2nd Rx</td>\n",
       "      <td>189</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>26.46%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Albon Bolus</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Baytril</td>\n",
       "      <td>330</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>21.52%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Baytril As 2nd Rx</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>94.34%</td>\n",
       "      <td>1.89%</td>\n",
       "      <td>$</td>\n",
       "      <td>18.43</td>\n",
       "      <td>$</td>\n",
       "      <td>976.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Baytril As 3rd Rx</td>\n",
       "      <td>124</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>96.77%</td>\n",
       "      <td>14.52%</td>\n",
       "      <td>$</td>\n",
       "      <td>51.42</td>\n",
       "      <td>$</td>\n",
       "      <td>6,376.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Bio-Mycin</td>\n",
       "      <td>2,431</td>\n",
       "      <td>421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89</td>\n",
       "      <td>82.68%</td>\n",
       "      <td>3.66%</td>\n",
       "      <td>$</td>\n",
       "      <td>9 .17</td>\n",
       "      <td>$</td>\n",
       "      <td>22,295.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Bio-Myicn As 3rd Rx</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>98.86%</td>\n",
       "      <td>19.32%</td>\n",
       "      <td>$</td>\n",
       "      <td>5 .15</td>\n",
       "      <td>$</td>\n",
       "      <td>453.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Borgal</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Ceftiflex</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Draxxin</td>\n",
       "      <td>11,887</td>\n",
       "      <td>1 ,326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>792</td>\n",
       "      <td>88.84%</td>\n",
       "      <td>6.66%</td>\n",
       "      <td>$</td>\n",
       "      <td>34.38</td>\n",
       "      <td>$</td>\n",
       "      <td>4 08,675.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Draxxin As 2nd Rx</td>\n",
       "      <td>1,115</td>\n",
       "      <td>152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128</td>\n",
       "      <td>86.37%</td>\n",
       "      <td>11.48%</td>\n",
       "      <td>$</td>\n",
       "      <td>28.76</td>\n",
       "      <td>$</td>\n",
       "      <td>32,067.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Draxxin As 3rd Rx</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Excede</td>\n",
       "      <td>160</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>88.75%</td>\n",
       "      <td>6.25%</td>\n",
       "      <td>$</td>\n",
       "      <td>23.41</td>\n",
       "      <td>$</td>\n",
       "      <td>3,745.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Excede As 2nd Rx</td>\n",
       "      <td>1,475</td>\n",
       "      <td>329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212</td>\n",
       "      <td>77.69%</td>\n",
       "      <td>14.37%</td>\n",
       "      <td>$</td>\n",
       "      <td>34.44</td>\n",
       "      <td>$</td>\n",
       "      <td>50,799.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Excede As 3rd Rx</td>\n",
       "      <td>637</td>\n",
       "      <td>56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159</td>\n",
       "      <td>91.21%</td>\n",
       "      <td>24.96%</td>\n",
       "      <td>$</td>\n",
       "      <td>17.55</td>\n",
       "      <td>$</td>\n",
       "      <td>11,179.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Excenel</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Hexasol</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>LA-200</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Mass Rx Bio-Mycin</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "      <td>$</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                    0       1       2    3     4        5  \\\n",
       "0            0        Moderate Risk  52,113   6,533  3.0  ,206   87.46%   \n",
       "1            1           300 PRO LA       -       -  NaN     -    0.00%   \n",
       "2            2                 A180       -       -  NaN     -    0.00%   \n",
       "3            3       A180 As 2nd Rx       -       -  NaN     -    0.00%   \n",
       "4            4               Adspec       -       -  NaN     -    0.00%   \n",
       "5            5              Advocin     918      43  NaN   145   95.32%   \n",
       "6            6    Advocin As 2nd Rx     189       -  NaN    50  100.00%   \n",
       "7            7          Albon Bolus       -       -  NaN     -    0.00%   \n",
       "8            8              Baytril     330       -  NaN    71  100.00%   \n",
       "9            9    Baytril As 2nd Rx      53       3  NaN     1   94.34%   \n",
       "10          10    Baytril As 3rd Rx     124       4  NaN    18   96.77%   \n",
       "11          11            Bio-Mycin   2,431     421  NaN    89   82.68%   \n",
       "12          12  Bio-Myicn As 3rd Rx      88       1  NaN    17   98.86%   \n",
       "13          13               Borgal       -       -  NaN     -    0.00%   \n",
       "14          14            Ceftiflex       -       -  NaN     -    0.00%   \n",
       "15          15              Draxxin  11,887  1 ,326  NaN   792   88.84%   \n",
       "16          16    Draxxin As 2nd Rx   1,115     152  NaN   128   86.37%   \n",
       "17          17    Draxxin As 3rd Rx       -       -  NaN     -    0.00%   \n",
       "18          18               Excede     160      18  NaN    10   88.75%   \n",
       "19          19     Excede As 2nd Rx   1,475     329  NaN   212   77.69%   \n",
       "20          20     Excede As 3rd Rx     637      56  NaN   159   91.21%   \n",
       "21          21              Excenel       -       -  NaN     -    0.00%   \n",
       "22          22              Hexasol       -       -  NaN     -    0.00%   \n",
       "23          23               LA-200       -       -  NaN     -    0.00%   \n",
       "24          24    Mass Rx Bio-Mycin       -       -  NaN     -    0.00%   \n",
       "\n",
       "         6  7      8  9            10  \n",
       "0    6.15%  $  20.96  $  1,092,142.54  \n",
       "1    0.00%  $      -  $             -  \n",
       "2    0.00%  $      -  $             -  \n",
       "3    0.00%  $      -  $             -  \n",
       "4    0.00%  $      -  $             -  \n",
       "5   15.80%  $  35.27  $     32,376.71  \n",
       "6   26.46%  $      -  $             -  \n",
       "7    0.00%  $      -  $             -  \n",
       "8   21.52%  $      -  $             -  \n",
       "9    1.89%  $  18.43  $        976.99  \n",
       "10  14.52%  $  51.42  $      6,376.70  \n",
       "11   3.66%  $  9 .17  $     22,295.31  \n",
       "12  19.32%  $  5 .15  $        453.20  \n",
       "13   0.00%  $      -  $             -  \n",
       "14   0.00%  $      -  $             -  \n",
       "15   6.66%  $  34.38  $   4 08,675.06  \n",
       "16  11.48%  $  28.76  $     32,067.40  \n",
       "17   0.00%  $      -  $             -  \n",
       "18   6.25%  $  23.41  $      3,745.20  \n",
       "19  14.37%  $  34.44  $     50,799.00  \n",
       "20  24.96%  $  17.55  $     11,179.35  \n",
       "21   0.00%  $      -  $             -  \n",
       "22   0.00%  $      -  $             -  \n",
       "23   0.00%  $      -  $             -  \n",
       "24   0.00%  $      -  $             -  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open(path_master+'October 2018 - Antibiotic by Risk3.csv') as fp:\n",
    "    df_ABR1 = pd.read_csv(fp)\n",
    "df_ABR1.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df_final.loc[df_final['Year'] == '2018']\n",
    "#len(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is not to be used yet. To clean df_ABR\n",
    "\n",
    "def convert_1(x):\n",
    "    if re.search(pattern = r'\\w+',string=x):\n",
    "        return x\n",
    "    x=x.strip()\n",
    "    if x[-1]=='%':\n",
    "        return float(x.replace('%,'))\n",
    "    if x=='-':\n",
    "        return 0\n",
    "    if x[0]=='$':\n",
    "        return float(x[1:].replace(',','').replace('-','0'))\n",
    "\n",
    "def ABR_Clean(df):\n",
    "    \"\"\"Cleans fully merged df_ABR columns to ensure appropriate dtypes/formats\"\"\"\n",
    "    for col in df.columns:\n",
    "        df[col]=df[col].apply(convert_1)\n",
    "    \n",
    "# Run this below to convert to .py file before pushing to GitHub\n",
    "get_ipython().system('jupyter nbconvert --to script Antibiotics_by_Risk.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean FULL df_ABR\n",
    "df_ABR = df_final\n",
    "for i in range(len(df_ABR)):\n",
    "    for j in ['Treated','Repulls','Mortalities']:\n",
    "        if df_ABR.iloc[i].loc[j] == '-':\n",
    "            df_ABR.iloc[i].loc[j] = 0\n",
    "        else:\n",
    "            m = df_ABR.iloc[i].loc[j]\n",
    "            m = m.replace(' ','')\n",
    "            df_ABR.iloc[i].loc[j] = m.replace(',','')\n",
    "\n",
    "# Change str -> int for numerical columns\n",
    "# df_ABR['Treated'] = df_ABR['Treated'].apply(lambda x: int(x))\n",
    "# df_ABR['Repulls'] = df_ABR['Repulls'].apply(lambda x: int(x))\n",
    "# df_ABR['Mortalities'] = df_ABR['Mortalities'].apply(lambda x: int(x))\n",
    "\n",
    "df_ABR['Treated'] = df_ABR['Treated'].convert_objects(convert_numeric=True)\n",
    "df_ABR['Repulls'] = df_ABR['Repulls'].convert_objects(convert_numeric=True)\n",
    "df_ABR['Mortalities'] = df_ABR['Mortalities'].convert_objects(convert_numeric=True)\n",
    "\n",
    "# Remove dollar signs from columns\n",
    "df_ABR['Treatment $'] = df_ABR['Treatment $'].apply(lambda x: x[1:])\n",
    "df_ABR['$/Hd/Rx'] = df_ABR['$/Hd/Rx'].apply(lambda x: x[1:])\n",
    "\n",
    "# Remove dashes from columns\n",
    "for i in range(len(df_ABR)):\n",
    "    for j in ['$/Hd/Rx','Treatment $']:\n",
    "        if df_ABR.iloc[i].loc[j] == '-':\n",
    "            df_ABR.iloc[i].loc[j] = 0.0\n",
    "        else:\n",
    "            m = df_ABR.iloc[i].loc[j]\n",
    "            df_ABR.iloc[i].loc[j] = m.replace(',','')\n",
    "            m = m.replace(' ','')\n",
    "            df_ABR.iloc[i].loc[j] = m.replace(',','')\n",
    "\n",
    "# Change str -> float for numerical columns\n",
    "df_ABR['Treatment $'] = df_ABR['Treatment $'].convert_objects(convert_numeric=True)\n",
    "df_ABR['$/Hd/Rx'] = df_ABR['$/Hd/Rx'].convert_objects(convert_numeric=True)\n",
    "\n",
    "# Remove percent signs from columns and convery str -> float\n",
    "df_ABR['Treatment Success(%)'] = df_ABR['Treatment Success(%)'].apply(lambda x: float(x[:-1]))\n",
    "df_ABR['Case Fatality Rate(%)'] = df_ABR['Case Fatality Rate(%)'].apply(lambda x: float(x[:-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
