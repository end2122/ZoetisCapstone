{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "path_master = r'C:/Users/endwy/Documents/Columbia MSBA/Spring 2019/E4524 - Analytics in Practice/Data/Csv/'\n",
    "file_names = list()\n",
    "for path, subdirs, files in os.walk(path_master):\n",
    "    for filename in files:\n",
    "        file_names.append(filename)\n",
    "df_final = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Functions to read/clean CSVs -- produces df_ABR.csv final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x):\n",
    "    x = str(x)\n",
    "    x = x.strip().replace(',','')\n",
    "    x = x.replace(' ','')\n",
    "    if re.search(pattern = r'\\w+',string=x):\n",
    "        return x\n",
    "    if x=='-':\n",
    "        return 0\n",
    "#     if x[0]=='$':\n",
    "#         return float(x[1:].replace(',','').replace('-','0'))\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def add_season(month):\n",
    "    springs = ['February','March']\n",
    "    falls = ['September','October','November','December']\n",
    "    if month in springs:\n",
    "        season = \"Spring\"\n",
    "    elif month in falls:\n",
    "        season = \"Fall\"\n",
    "    else: \n",
    "        season = \"Other\"\n",
    "    return season\n",
    "\n",
    "def merge_cols(df,col1,col2):\n",
    "    \"\"\"Merge any two columns in df\"\"\"\n",
    "    for i in range(len(df)):\n",
    "        df.iloc[i].loc[col1] = (df.iloc[i].loc[col1])+(df.iloc[i].loc[col2])\n",
    "    del df[col2]\n",
    "    \n",
    "def add_time(df_ABR1):\n",
    "    \"\"\"Add Month, Year, Season columns based on read-in file name\"\"\"\n",
    "    mon=re.search(r'\\w+', file_name)\n",
    "    df_ABR1['Month']= file_name[mon.start():mon.end()]\n",
    "    y=re.search(r'\\d+', file_name)\n",
    "    df_ABR1['Year'] = file_name[y.start():y.end()]            \n",
    "    \n",
    "def type1(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 columns, missing 7,9, merge 3,4\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','8','10'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '8':'$/Hd/Rx','10':'Treatment $'}, inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type2(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 6,8\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                              usecols=['0','1','2','3','4','5','7','9'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                            '5':'Case Fatality Rate(%)', '7':'$/Hd/Rx', '9':'Treatment $',}, \n",
    "                       inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type3(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"base case\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                          skiprows=[0], \n",
    "                          usecols=['Unnamed: 1', 'Treated', 'Repulls', 'Mortalities', 'Treatment Success',\n",
    "                                   'Case Fatality Rate','$/Hd/Rx', 'Treatment $'])\n",
    "    df_ABR1.rename(columns={'Unnamed: 1': 'Drug', 'Treatment Success':'Treatment Success(%)',\n",
    "                        'Case Fatality Rate':'Case Fatality Rate(%)'}, inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type4(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 7,9, concatenate Treatment column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','8','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'RepullsB', '4':'Mortalities', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '8':'$/Hd/Rx',\n",
    "                        '10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column and Repulls column\n",
    "    merge_cols(df_ABR1,'Treatment $','Treatment $B')\n",
    "    merge_cols(df_ABR1,'Repulls','RepullsB')\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type5(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 column, missing 6,8, merge 9,10\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','7','9','10'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                        '5':'Case Fatality Rate(%)', '7':'$/Hd/Rx', \n",
    "                        '9':'Treatment $','10':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    merge_cols(df_ABR1,'Treatment $','Treatment $B')\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type6(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 column, concatenate Treatment column\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','3','4','5','6','7','8','9','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '3':'Repulls', '4':'Mortalities','5':'MortalitiesB','6':'Treatment Success(%)', \n",
    "                        '7':'Case Fatality Rate(%)', '8':'$/Hd/Rx', '9':'$/Hd/RxB',\n",
    "                        '10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    merge_cols(df_ABR1,'$/Hd/Rx','$/Hd/RxB')\n",
    "    merge_cols(df_ABR1,'Treatment $','Treatment $B')\n",
    "    df_ABR1['Treated']=df_ABR1['Treated'].apply(lambda x: x.replace(' ',''))\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type7(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 8,10\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','4','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '4':'Mortalities', '6':'Treatment Success(%)', \n",
    "                        '7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type8(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 columns, missing 8,9, concatenate Mortalities column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','7','10'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '7':'$/Hd/Rx','10':'Treatment $'},\n",
    "                   inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type9(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"13 columns, missing 10,12\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','5','6','8','9','11','13'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated','2':'Repulls','3':'RepullsB','5':'Mortalities','6':'MortalitiesB',\n",
    "                            '8':'Treatment Success(%)','9':'Case Fatality Rate(%)','11':'$/Hd/Rx','13':'Treatment $'},\n",
    "                   inplace=True)\n",
    "    # Concatenate Repulls & Mortalities columns\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    merge_cols(df_ABR1,'Repulls','RepullsB')\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type10(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 8, merge 3,4\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','7','9'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '7':'$/Hd/Rx','9':'Treatment $'}, \n",
    "                   inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type11(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 3,8,10 merge 4,5\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','4','5','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '4':'Mortalities', '5':'MortalitiesB',\n",
    "                            '6':'Treatment Success(%)', '7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "     # Concatenate mortalities column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type12(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 8,10, merge 2,3 and 4,5\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'RepullsB','4':'Mortalities','5':'MortalitiesB',\n",
    "                            '6':'Treatment Success(%)','7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "    # Concatenate Repulls & Mortalities columns\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    merge_cols(df_ABR1,'Repulls','RepullsB')\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type13(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 column, missing 7,9, merge 2,3 and 10,11\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','8','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated','2':'Repulls', '3':'RepullsB', '4':'Mortalities',\n",
    "                            '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', \n",
    "                            '8':'$/Hd/Rx','10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    merge_cols(df_ABR1,'Repulls','RepullsB')\n",
    "    merge_cols(df_ABR1,'Treatment $','Treatment $B')\n",
    "    df_ABR1['Treated']=df_ABR1['Treated'].apply(lambda x: x.replace(' ',''))\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type14(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 7,8\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                              usecols=['0','1','2','3','4','5','6','9'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                            '5':'Case Fatality Rate(%)', '6':'$/Hd/Rx', '9':'Treatment $',}, \n",
    "                       inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use functions to clean each month's CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JANUARY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'January\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5' or file_num == '8'or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7'or file_num == '9':\n",
    "                type2(path_master,title,file_num)    \n",
    "\n",
    "# FEBRUARY 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'February\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5'or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4'or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '7'or file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        elif file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '5':\n",
    "                type8(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '8':\n",
    "                type7(path_master,title,file_num)\n",
    "        \n",
    "# MARCH 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'March\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type7(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '5'or file_num == '6'or file_num == '7'or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type9(path_master,title,file_num)\n",
    "    \n",
    "# APRIL 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'April\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '3' or file_num == '5' or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '7':\n",
    "                type6(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        elif file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num=='4' or file_num=='6' or file_num=='7' or file_num=='10':\n",
    "                type1(path_master,title,file_num)  \n",
    "            elif file_num == '3' or file_num=='5' or file_num=='9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '8':\n",
    "                type7(path_master,title,file_num)\n",
    "                \n",
    "# MAY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'May\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '5' or file_num == '6'or file_num == '7'or file_num == '8'or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "                \n",
    "# JUNE 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'June\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type7(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '4' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '5' or file_num == '6' or file_num == '7'or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type5(path_master,title,file_num)\n",
    "                \n",
    "# JULY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'July\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '5' or file_num == '6' or file_num == '7' or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type12(path_master,title,file_num)\n",
    "                \n",
    "# AUGUST 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'August\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '7' or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '5' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type10(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type12(path_master,title,file_num)\n",
    "                \n",
    "# SEPTEMBER 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'September\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '3' or file_num == '5' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "                \n",
    "# OCTOBER 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'October\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type12(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type13(path_master,title,file_num)\n",
    "            elif file_num == '5':\n",
    "                type14(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            \n",
    "# NOVEMBER 2017 & 2018 (note: no 2017 or 2018 file)\n",
    "\n",
    "# DECEMBER 2017 & 2018 (note: no 2018 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'December\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '4' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "\n",
    "# Remove percent signs from columns and convery str -> float\n",
    "df_final['Treatment Success(%)'] = df_final['Treatment Success(%)'].apply(lambda x: float(x[:-1]))\n",
    "df_final['Case Fatality Rate(%)'] = df_final['Case Fatality Rate(%)'].apply(lambda x: float(x[:-1]))\n",
    "\n",
    "# add season column\n",
    "df_final['Season'] = df_final['Month'].apply(add_season)\n",
    "\n",
    "# Remove dollar signs from columns\n",
    "df_final['Treatment $'] = df_final['Treatment $'].apply(lambda x: x[1:])\n",
    "df_final['$/Hd/Rx'] = df_final['$/Hd/Rx'].apply(lambda x: x[1:])\n",
    "\n",
    "#clean number formats\n",
    "for col in df_final.columns:\n",
    "    df_final[col] = df_final[col].apply(conv)\n",
    "\n",
    "# dtypes to numeric\n",
    "col_to_num = ['Treated','Repulls','Mortalities','Treatment $','$/Hd/Rx']\n",
    "for i in col_to_num:\n",
    "    df_final[i] = df_final[i].convert_objects(convert_numeric=True)\n",
    "\n",
    "# fill zeroes\n",
    "df_final.fillna(0)\n",
    "\n",
    "# Save out df_ABR\n",
    "import csv\n",
    "df_final.to_csv(path_master+\"/df_ABR.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open full df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open(path_master+'df_ABR.csv') as fp:\n",
    "    df_final = pd.read_csv(fp)\n",
    "del df_final['Unnamed: 0']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
