{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "path_master = r'C:/Users/endwy/Documents/Columbia MSBA/Spring 2019/E4524 - Analytics in Practice/Data/Csv/'\n",
    "file_names = list()\n",
    "for path, subdirs, files in os.walk(path_master):\n",
    "    for filename in files:\n",
    "        file_names.append(filename)\n",
    "df_final = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Functions to read/clean CSVs -- produces df_ABR.csv final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x):\n",
    "    x = str(x)\n",
    "    x = x.strip().replace(',','')\n",
    "    x = x.replace(' ','')\n",
    "    if re.search(pattern = r'\\w+',string=x):\n",
    "        return x\n",
    "    if x=='-':\n",
    "        return 0\n",
    "#     if x[0]=='$':\n",
    "#         return float(x[1:].replace(',','').replace('-','0'))\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def add_risk(df,fn):\n",
    "    \"\"\"Add Risk column based on file number\"\"\"  \n",
    "    if fn=='1':\n",
    "            df.drop(df.index[0],inplace=True)\n",
    "            df['Risk']='Low'\n",
    "    if fn=='2':\n",
    "            df['Risk']='Low'\n",
    "    if fn=='3':\n",
    "            df.drop(df.index[0])\n",
    "            df['Risk']='Moderate'\n",
    "    if fn=='4':\n",
    "            df['Risk']='Moderate'\n",
    "    if fn=='5':\n",
    "            df.drop(df.index[0])\n",
    "            df['Risk']='High'\n",
    "    if fn=='6':\n",
    "            df['Risk']='High'\n",
    "    if fn=='7':\n",
    "            df.drop(df.index[0])\n",
    "            df['Risk']='Ultra High'\n",
    "    if fn=='7':\n",
    "            df['Risk']='Ultra High'\n",
    "    if fn=='9':\n",
    "            df.drop(df.index[0])\n",
    "            df['Risk']='Natural'\n",
    "    if fn=='10':\n",
    "            df['Risk']='Natural'\n",
    "    \n",
    "        \n",
    "    \n",
    "def add_season(month):\n",
    "    springs = ['February','March']\n",
    "    falls = ['September','October','November','December']\n",
    "    if month in springs:\n",
    "        season = \"Spring\"\n",
    "    elif month in falls:\n",
    "        season = \"Fall\"\n",
    "    else: \n",
    "        season = \"Other\"\n",
    "    return season\n",
    "\n",
    "def merge_cols(df,col1,col2):\n",
    "    \"\"\"Merge any two columns in df\"\"\"\n",
    "    for i in range(len(df)):\n",
    "        df.iloc[i].loc[col1] = (df.iloc[i].loc[col1])+(df.iloc[i].loc[col2])\n",
    "    del df[col2]\n",
    "    \n",
    "def add_time(df_ABR1):\n",
    "    \"\"\"Add Month, Year, Season columns based on read-in file name\"\"\"\n",
    "    mon=re.search(r'\\w+', file_name)\n",
    "    df_ABR1['Month']= file_name[mon.start():mon.end()]\n",
    "    y=re.search(r'\\d+', file_name)\n",
    "    df_ABR1['Year'] = file_name[y.start():y.end()]            \n",
    "    \n",
    "def type1(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 columns, missing 7,9, merge 3,4\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','8','10'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '8':'$/Hd/Rx','10':'Treatment $'}, inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type2(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 6,8\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                              usecols=['0','1','2','3','4','5','7','9'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                            '5':'Case Fatality Rate(%)', '7':'$/Hd/Rx', '9':'Treatment $',}, \n",
    "                       inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type3(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"base case\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                          skiprows=[0], \n",
    "                          usecols=['Unnamed: 1', 'Treated', 'Repulls', 'Mortalities', 'Treatment Success',\n",
    "                                   'Case Fatality Rate','$/Hd/Rx', 'Treatment $'])\n",
    "    df_ABR1.rename(columns={'Unnamed: 1': 'Drug', 'Treatment Success':'Treatment Success(%)',\n",
    "                        'Case Fatality Rate':'Case Fatality Rate(%)'}, inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type4(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 7,9, concatenate Treatment column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','8','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'RepullsB', '4':'Mortalities', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '8':'$/Hd/Rx',\n",
    "                        '10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column and Repulls column\n",
    "    merge_cols(df_ABR1,'Treatment $','Treatment $B')\n",
    "    merge_cols(df_ABR1,'Repulls','RepullsB')\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type5(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 column, missing 6,8, merge 9,10\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','7','9','10'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                        '5':'Case Fatality Rate(%)', '7':'$/Hd/Rx', \n",
    "                        '9':'Treatment $','10':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    merge_cols(df_ABR1,'Treatment $','Treatment $B')\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type6(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 column, concatenate Treatment column\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','3','4','5','6','7','8','9','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '3':'Repulls', '4':'Mortalities','5':'MortalitiesB','6':'Treatment Success(%)', \n",
    "                        '7':'Case Fatality Rate(%)', '8':'$/Hd/Rx', '9':'$/Hd/RxB',\n",
    "                        '10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    merge_cols(df_ABR1,'$/Hd/Rx','$/Hd/RxB')\n",
    "    merge_cols(df_ABR1,'Treatment $','Treatment $B')\n",
    "    df_ABR1['Treated']=df_ABR1['Treated'].apply(lambda x: x.replace(' ',''))\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type7(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 8,10\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','4','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '4':'Mortalities', '6':'Treatment Success(%)', \n",
    "                        '7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type8(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 columns, missing 8,9, concatenate Mortalities column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','7','10'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '7':'$/Hd/Rx','10':'Treatment $'},\n",
    "                   inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type9(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"13 columns, missing 10,12\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','5','6','8','9','11','13'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated','2':'Repulls','3':'RepullsB','5':'Mortalities','6':'MortalitiesB',\n",
    "                            '8':'Treatment Success(%)','9':'Case Fatality Rate(%)','11':'$/Hd/Rx','13':'Treatment $'},\n",
    "                   inplace=True)\n",
    "    # Concatenate Repulls & Mortalities columns\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    merge_cols(df_ABR1,'Repulls','RepullsB')\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type10(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 8, merge 3,4\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','7','9'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '7':'$/Hd/Rx','9':'Treatment $'}, \n",
    "                   inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type11(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 3,8,10 merge 4,5\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','4','5','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '4':'Mortalities', '5':'MortalitiesB',\n",
    "                            '6':'Treatment Success(%)', '7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "     # Concatenate mortalities column\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type12(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 8,10, merge 2,3 and 4,5\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'RepullsB','4':'Mortalities','5':'MortalitiesB',\n",
    "                            '6':'Treatment Success(%)','7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "    # Concatenate Repulls & Mortalities columns\n",
    "    merge_cols(df_ABR1,'Mortalities','MortalitiesB')\n",
    "    merge_cols(df_ABR1,'Repulls','RepullsB')\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type13(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 column, missing 7,9, merge 2,3 and 10,11\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','8','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated','2':'Repulls', '3':'RepullsB', '4':'Mortalities',\n",
    "                            '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', \n",
    "                            '8':'$/Hd/Rx','10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    merge_cols(df_ABR1,'Repulls','RepullsB')\n",
    "    merge_cols(df_ABR1,'Treatment $','Treatment $B')\n",
    "    df_ABR1['Treated']=df_ABR1['Treated'].apply(lambda x: x.replace(' ',''))\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type14(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 7,8\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                              usecols=['0','1','2','3','4','5','6','9'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                            '5':'Case Fatality Rate(%)', '6':'$/Hd/Rx', '9':'Treatment $',}, \n",
    "                       inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    add_risk(df_ABR1,fn)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use functions to clean each month's CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JANUARY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'January\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5' or file_num == '8'or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7'or file_num == '9':\n",
    "                type2(path_master,title,file_num)    \n",
    "\n",
    "# FEBRUARY 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'February\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5'or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4'or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '7'or file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        elif file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '5':\n",
    "                type8(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '8':\n",
    "                type7(path_master,title,file_num)\n",
    "        \n",
    "# MARCH 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'March\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type7(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '5'or file_num == '6'or file_num == '7'or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type9(path_master,title,file_num)\n",
    "    \n",
    "# APRIL 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'April\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '3' or file_num == '5' or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '7':\n",
    "                type6(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        elif file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num=='4' or file_num=='6' or file_num=='7' or file_num=='10':\n",
    "                type1(path_master,title,file_num)  \n",
    "            elif file_num == '3' or file_num=='5' or file_num=='9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '8':\n",
    "                type7(path_master,title,file_num)\n",
    "                \n",
    "# MAY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'May\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '5' or file_num == '6'or file_num == '7'or file_num == '8'or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "                \n",
    "# JUNE 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'June\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type7(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '4' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '5' or file_num == '6' or file_num == '7'or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type5(path_master,title,file_num)\n",
    "                \n",
    "# JULY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'July\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '5' or file_num == '6' or file_num == '7' or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type12(path_master,title,file_num)\n",
    "                \n",
    "# AUGUST 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'August\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '7' or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '5' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type10(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type12(path_master,title,file_num)\n",
    "                \n",
    "# SEPTEMBER 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'September\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '3' or file_num == '5' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "                \n",
    "# OCTOBER 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'October\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type12(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type13(path_master,title,file_num)\n",
    "            elif file_num == '5':\n",
    "                type14(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            \n",
    "# NOVEMBER 2017 & 2018 (note: no 2017 or 2018 file)\n",
    "\n",
    "# DECEMBER 2017 & 2018 (note: no 2018 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'December\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '4' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "\n",
    "# Remove percent signs from columns and convery str -> float\n",
    "df_final['Treatment Success(%)'] = df_final['Treatment Success(%)'].apply(lambda x: float(x[:-1]))\n",
    "df_final['Case Fatality Rate(%)'] = df_final['Case Fatality Rate(%)'].apply(lambda x: float(x[:-1]))\n",
    "\n",
    "# add season column\n",
    "df_final['Season'] = df_final['Month'].apply(add_season)\n",
    "\n",
    "# Remove dollar signs from columns\n",
    "df_final['Treatment $'] = df_final['Treatment $'].apply(lambda x: x[1:])\n",
    "df_final['$/Hd/Rx'] = df_final['$/Hd/Rx'].apply(lambda x: x[1:])\n",
    "\n",
    "#clean number formats\n",
    "for col in df_final.columns:\n",
    "    df_final[col] = df_final[col].apply(conv)\n",
    "\n",
    "# dtypes to numeric\n",
    "col_to_num = ['Treated','Repulls','Mortalities','Treatment $','$/Hd/Rx']\n",
    "for i in col_to_num:\n",
    "    df_final[i] = df_final[i].convert_objects(convert_numeric=True)\n",
    "\n",
    "# fill zeroes\n",
    "df_final.fillna(0)\n",
    "\n",
    "# Save out df_ABR\n",
    "import csv\n",
    "df_final.to_csv(path_master+\"/df_ABR.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open full df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$/Hd/Rx</th>\n",
       "      <th>Case Fatality Rate(%)</th>\n",
       "      <th>Drug</th>\n",
       "      <th>Month</th>\n",
       "      <th>Mortalities</th>\n",
       "      <th>Repulls</th>\n",
       "      <th>Risk</th>\n",
       "      <th>Treated</th>\n",
       "      <th>Treatment $</th>\n",
       "      <th>Treatment Success(%)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>300PROLA</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A180</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A180As2ndRx</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Adspec</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.13</td>\n",
       "      <td>9.86</td>\n",
       "      <td>Advocin</td>\n",
       "      <td>January</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>142</td>\n",
       "      <td>5130.82</td>\n",
       "      <td>83.80</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.34</td>\n",
       "      <td>16.48</td>\n",
       "      <td>AdvocinAs2ndRx</td>\n",
       "      <td>January</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>716</td>\n",
       "      <td>20291.44</td>\n",
       "      <td>99.86</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>AlbonBolus</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.88</td>\n",
       "      <td>25.00</td>\n",
       "      <td>Baytril</td>\n",
       "      <td>January</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4</td>\n",
       "      <td>91.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22.40</td>\n",
       "      <td>9.93</td>\n",
       "      <td>BaytrilAs2ndRx</td>\n",
       "      <td>January</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1128</td>\n",
       "      <td>25267.20</td>\n",
       "      <td>99.91</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.96</td>\n",
       "      <td>33.33</td>\n",
       "      <td>BaytrilAs3rdRx</td>\n",
       "      <td>January</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>9</td>\n",
       "      <td>206.64</td>\n",
       "      <td>77.78</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.21</td>\n",
       "      <td>13.89</td>\n",
       "      <td>Bio-Mycin</td>\n",
       "      <td>January</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>36</td>\n",
       "      <td>187.38</td>\n",
       "      <td>66.67</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.96</td>\n",
       "      <td>20.00</td>\n",
       "      <td>Bio-MyicnAs3rdRx</td>\n",
       "      <td>January</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>15</td>\n",
       "      <td>59.33</td>\n",
       "      <td>80.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Borgal</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Ceftiflex</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38.15</td>\n",
       "      <td>5.59</td>\n",
       "      <td>Draxxin</td>\n",
       "      <td>January</td>\n",
       "      <td>430.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>7694</td>\n",
       "      <td>293487.63</td>\n",
       "      <td>92.15</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30.20</td>\n",
       "      <td>8.02</td>\n",
       "      <td>DraxxinAs2ndRx</td>\n",
       "      <td>January</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>187</td>\n",
       "      <td>5646.47</td>\n",
       "      <td>87.17</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>DraxxinAs3rdRx</td>\n",
       "      <td>January</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20.90</td>\n",
       "      <td>23.81</td>\n",
       "      <td>Excede</td>\n",
       "      <td>January</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>42</td>\n",
       "      <td>877.80</td>\n",
       "      <td>69.05</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20.28</td>\n",
       "      <td>19.66</td>\n",
       "      <td>ExcedeAs2ndRx</td>\n",
       "      <td>January</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>234</td>\n",
       "      <td>4745.52</td>\n",
       "      <td>99.15</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00</td>\n",
       "      <td>44.44</td>\n",
       "      <td>ExcedeAs3rdRx</td>\n",
       "      <td>January</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    $/Hd/Rx  Case Fatality Rate(%)              Drug    Month  Mortalities  \\\n",
       "0      0.00                   0.00          300PROLA  January          0.0   \n",
       "1      0.00                   0.00              A180  January          0.0   \n",
       "2      0.00                   0.00       A180As2ndRx  January          0.0   \n",
       "3      0.00                   0.00            Adspec  January          0.0   \n",
       "4     36.13                   9.86           Advocin  January         14.0   \n",
       "5     28.34                  16.48    AdvocinAs2ndRx  January        118.0   \n",
       "6      0.00                   0.00        AlbonBolus  January          0.0   \n",
       "7     22.88                  25.00           Baytril  January          1.0   \n",
       "8     22.40                   9.93    BaytrilAs2ndRx  January        112.0   \n",
       "9     22.96                  33.33    BaytrilAs3rdRx  January          3.0   \n",
       "10     5.21                  13.89         Bio-Mycin  January          5.0   \n",
       "11     3.96                  20.00  Bio-MyicnAs3rdRx  January          3.0   \n",
       "12     0.00                   0.00            Borgal  January          0.0   \n",
       "13     0.00                   0.00         Ceftiflex  January          0.0   \n",
       "14    38.15                   5.59           Draxxin  January        430.0   \n",
       "15    30.20                   8.02    DraxxinAs2ndRx  January         15.0   \n",
       "16     0.00                   0.00    DraxxinAs3rdRx  January          0.0   \n",
       "17    20.90                  23.81            Excede  January         10.0   \n",
       "18    20.28                  19.66     ExcedeAs2ndRx  January         46.0   \n",
       "19     0.00                  44.44     ExcedeAs3rdRx  January          4.0   \n",
       "\n",
       "    Repulls Risk  Treated  Treatment $  Treatment Success(%)  Year Season  \n",
       "0       0.0  Low        0         0.00                  0.00  2018  Other  \n",
       "1       0.0  Low        0         0.00                  0.00  2018  Other  \n",
       "2       0.0  Low        0         0.00                  0.00  2018  Other  \n",
       "3       0.0  Low        0         0.00                  0.00  2018  Other  \n",
       "4      23.0  Low      142      5130.82                 83.80  2018  Other  \n",
       "5       1.0  Low      716     20291.44                 99.86  2018  Other  \n",
       "6       0.0  Low        0         0.00                  0.00  2018  Other  \n",
       "7       4.0  Low        4        91.52                  0.00  2018  Other  \n",
       "8       1.0  Low     1128     25267.20                 99.91  2018  Other  \n",
       "9       2.0  Low        9       206.64                 77.78  2018  Other  \n",
       "10     12.0  Low       36       187.38                 66.67  2018  Other  \n",
       "11      3.0  Low       15        59.33                 80.00  2018  Other  \n",
       "12      0.0  Low        0         0.00                  0.00  2018  Other  \n",
       "13      0.0  Low        0         0.00                  0.00  2018  Other  \n",
       "14    604.0  Low     7694    293487.63                 92.15  2018  Other  \n",
       "15     24.0  Low      187      5646.47                 87.17  2018  Other  \n",
       "16      0.0  Low        0         0.00                  0.00  2018  Other  \n",
       "17     13.0  Low       42       877.80                 69.05  2018  Other  \n",
       "18      2.0  Low      234      4745.52                 99.15  2018  Other  \n",
       "19      0.0  Low        9         0.00                100.00  2018  Other  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "with open(path_master+'df_ABR.csv') as fp:\n",
    "    df_final = pd.read_csv(fp)\n",
    "del df_final['Unnamed: 0']\n",
    "df_final.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
