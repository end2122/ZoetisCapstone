{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "path_master = r'C:/Users/endwy/Documents/Columbia MSBA/Spring 2019/E4524 - Analytics in Practice/Data/Csv/'\n",
    "file_names = list()\n",
    "for path, subdirs, files in os.walk(path_master):\n",
    "    for filename in files:\n",
    "        file_names.append(filename)\n",
    "df_final = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to read in CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_cols(df,col1,col2):\n",
    "    \"\"\"Merge any two columns in df\"\"\"\n",
    "    for i in range(len(df)):\n",
    "        df.iloc[i].loc[col1] = (df.iloc[i].loc[col1])+(df.iloc[i].loc[col2])\n",
    "    del df[col2]\n",
    "    \n",
    "def add_time(df_ABR1):\n",
    "    \"\"\"Add Month and Year column based on read-in file name\"\"\"\n",
    "    mon=re.search(r'\\w+', file_name)\n",
    "    df_ABR1['Month']= file_name[mon.start():mon.end()]\n",
    "    y=re.search(r'\\d+', file_name)\n",
    "    df_ABR1['Year'] = file_name[y.start():y.end()]\n",
    "    \n",
    "def type1(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 columns, missing 7,9, merge 3,4\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','8','10'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '8':'$/Hd/Rx','10':'Treatment $'}, inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type2(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 6,8\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                              usecols=['0','1','2','3','4','5','7','9'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                            '5':'Case Fatality Rate(%)', '7':'$/Hd/Rx', '9':'Treatment $',}, \n",
    "                       inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type3(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"base case\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                          skiprows=[0], \n",
    "                          usecols=['Unnamed: 1', 'Treated', 'Repulls', 'Mortalities', 'Treatment Success',\n",
    "                                   'Case Fatality Rate','$/Hd/Rx', 'Treatment $'])\n",
    "    df_ABR1.rename(columns={'Unnamed: 1': 'Drug', 'Treatment Success':'Treatment Success(%)',\n",
    "                        'Case Fatality Rate':'Case Fatality Rate(%)'}, inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type4(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 7,9, concatenate Treatment column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','8','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'RepullsB', '4':'Mortalities', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '8':'$/Hd/Rx',\n",
    "                        '10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Treatment $'] = (df_ABR1.iloc[i].loc['Treatment $'])+(df_ABR1.iloc[i].loc['Treatment $B'])\n",
    "    del df_ABR1['Treatment $B']\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Repulls'] = (df_ABR1.iloc[i].loc['Repulls'])+(df_ABR1.iloc[i].loc['RepullsB'])\n",
    "    del df_ABR1['RepullsB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type5(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 column, missing 6,8, merge 9,10\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','7','9','10'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                        '5':'Case Fatality Rate(%)', '7':'$/Hd/Rx', \n",
    "                        '9':'Treatment $','10':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Treatment $'] = (df_ABR1.iloc[i].loc['Treatment $'])+(df_ABR1.iloc[i].loc['Treatment $B'])\n",
    "    del df_ABR1['Treatment $B']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type6(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 column, concatenate Treatment column\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','3','4','5','6','7','8','9','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '3':'Repulls', '4':'Mortalities','5':'MortalitiesB','6':'Treatment Success(%)', \n",
    "                        '7':'Case Fatality Rate(%)', '8':'$/Hd/Rx', '9':'$/Hd/RxB',\n",
    "                        '10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "        df_ABR1.iloc[i].loc['$/Hd/Rx'] = (df_ABR1.iloc[i].loc['$/Hd/Rx'])+(df_ABR1.iloc[i].loc['$/Hd/RxB'])\n",
    "        df_ABR1.iloc[i].loc['Treatment $'] = (df_ABR1.iloc[i].loc['Treatment $'])+(df_ABR1.iloc[i].loc['Treatment $B'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    del df_ABR1['$/Hd/RxB']\n",
    "    del df_ABR1['Treatment $B']\n",
    "    df_ABR1['Treated']=df_ABR1['Treated'].apply(lambda x: x.replace(' ',''))\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type7(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 8,10\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','4','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '4':'Mortalities', '6':'Treatment Success(%)', \n",
    "                        '7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type8(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"10 columns, missing 8,9, concatenate Mortalities column\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','7','10'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '7':'$/Hd/Rx','10':'Treatment $'},\n",
    "                   inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type9(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"13 columns, missing 10,12\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','5','6','8','9','11','13'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated','2':'Repulls','3':'RepullsB','5':'Mortalities','6':'MortalitiesB',\n",
    "                            '8':'Treatment Success(%)','9':'Case Fatality Rate(%)','11':'$/Hd/Rx','13':'Treatment $'},\n",
    "                   inplace=True)\n",
    "    # Concatenate Repulls & Mortalities columns\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "        df_ABR1.iloc[i].loc['Repulls'] = (df_ABR1.iloc[i].loc['Repulls'])+(df_ABR1.iloc[i].loc['RepullsB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    del df_ABR1['RepullsB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "\n",
    "def type10(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 8, merge 3,4\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp, \n",
    "                              usecols=['0','1','2','3','4','5','6','7','9'],\n",
    "                              keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'MortalitiesB', \n",
    "                        '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', '7':'$/Hd/Rx','9':'Treatment $'}, \n",
    "                   inplace=True)\n",
    "    # Concatenate mortalities column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type11(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 3,8,10 merge 4,5\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','4','5','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '4':'Mortalities', '5':'MortalitiesB',\n",
    "                            '6':'Treatment Success(%)', '7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "     # Concatenate mortalities column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type12(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 columns, missing 8,10, merge 2,3 and 4,5\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','7','9','11'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'RepullsB','4':'Mortalities','5':'MortalitiesB',\n",
    "                            '6':'Treatment Success(%)','7':'Case Fatality Rate(%)', '9':'$/Hd/Rx', '11':'Treatment $',\n",
    "                        }, inplace=True)\n",
    "    # Concatenate Repulls & Mortalities columns\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Mortalities'] = (df_ABR1.iloc[i].loc['Mortalities'])+(df_ABR1.iloc[i].loc['MortalitiesB'])\n",
    "        df_ABR1.iloc[i].loc['Repulls'] = (df_ABR1.iloc[i].loc['Repulls'])+(df_ABR1.iloc[i].loc['RepullsB'])\n",
    "    del df_ABR1['MortalitiesB']\n",
    "    del df_ABR1['RepullsB']\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type13(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"11 column, missing 7,9, merge 2,3 and 10,11\"\"\"\n",
    "    with open(path_master+title+file_num+'.csv') as fp:\n",
    "                df_ABR1 = pd.read_csv(fp,\n",
    "                         usecols=['0','1','2','3','4','5','6','8','10','11'],\n",
    "                         keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated','2':'Repulls', '3':'RepullsB', '4':'Mortalities',\n",
    "                            '5':'Treatment Success(%)', '6':'Case Fatality Rate(%)', \n",
    "                            '8':'$/Hd/Rx','10':'Treatment $','11':'Treatment $B'}, inplace=True)\n",
    "    # Concatenate Treatment $ column\n",
    "    for i in range(len(df_ABR1)):\n",
    "        df_ABR1.iloc[i].loc['Repulls'] = (df_ABR1.iloc[i].loc['Repulls'])+(df_ABR1.iloc[i].loc['RepullsB'])\n",
    "        df_ABR1.iloc[i].loc['Treatment $'] = (df_ABR1.iloc[i].loc['Treatment $'])+(df_ABR1.iloc[i].loc['Treatment $B'])\n",
    "    del df_ABR1['RepullsB']\n",
    "    del df_ABR1['Treatment $B']\n",
    "    df_ABR1['Treated']=df_ABR1['Treated'].apply(lambda x: x.replace(' ',''))\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n",
    "def type14(pm,tt,fn,d='.csv'):\n",
    "    \"\"\"9 columns, missing 7,8\"\"\"\n",
    "    with open(pm+tt+fn+d) as fp:\n",
    "        df_ABR1 = pd.read_csv(fp,\n",
    "                              usecols=['0','1','2','3','4','5','6','9'], keep_default_na=False)\n",
    "    df_ABR1.rename(columns={'0':'Drug', '1':'Treated', '2':'Repulls', '3':'Mortalities', '4':'Treatment Success(%)', \n",
    "                            '5':'Case Fatality Rate(%)', '6':'$/Hd/Rx', '9':'Treatment $',}, \n",
    "                       inplace=True)\n",
    "    add_time(df_ABR1)\n",
    "    global df_final\n",
    "    df_final = pd.concat([df_final,df_ABR1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use functions to clean each month's CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JANUARY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'January\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5' or file_num == '8'or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7'or file_num == '9':\n",
    "                type2(path_master,title,file_num)    \n",
    "\n",
    "# FEBRUARY 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'February\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5'or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4'or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '7'or file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        elif file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '5':\n",
    "                type8(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '8':\n",
    "                type7(path_master,title,file_num)\n",
    "        \n",
    "# MARCH 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'March\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type7(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '5'or file_num == '6'or file_num == '7'or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type9(path_master,title,file_num)\n",
    "    \n",
    "# APRIL 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'April\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '3' or file_num == '5' or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '7':\n",
    "                type6(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        elif file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num=='4' or file_num=='6' or file_num=='7' or file_num=='10':\n",
    "                type1(path_master,title,file_num)  \n",
    "            elif file_num == '3' or file_num=='5' or file_num=='9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '8':\n",
    "                type7(path_master,title,file_num)\n",
    "                \n",
    "# MAY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'May\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4' or file_num == '5' or file_num == '6'or file_num == '7'or file_num == '8'or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "                \n",
    "# JUNE 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'June\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type7(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '4' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '5' or file_num == '6' or file_num == '7'or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type5(path_master,title,file_num)\n",
    "                \n",
    "# JULY 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'July\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '5' or file_num == '6' or file_num == '7' or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type12(path_master,title,file_num)\n",
    "                \n",
    "# AUGUST 2017 & 2018\n",
    "for file_name in file_names:\n",
    "    pattern = r'August\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '7' or file_num == '8':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '5':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '6':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '9':\n",
    "                type4(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type7(path_master,title,file_num)\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4' or file_num == '5' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            elif file_num == '3':\n",
    "                type10(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '8':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '10':\n",
    "                type12(path_master,title,file_num)\n",
    "                \n",
    "# SEPTEMBER 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'September\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '3' or file_num == '5' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "                \n",
    "# OCTOBER 2017 & 2018 (note: no 2017 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'October\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2018\n",
    "        if file_name.split()[1] == '2018':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2':\n",
    "                type12(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '4':\n",
    "                type13(path_master,title,file_num)\n",
    "            elif file_num == '5':\n",
    "                type14(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)\n",
    "            \n",
    "# NOVEMBER 2017 & 2018 (note: no 2017 or 2018 file)\n",
    "\n",
    "# DECEMBER 2017 & 2018 (note: no 2018 file)\n",
    "for file_name in file_names:\n",
    "    pattern = r'December\\s+\\d+\\s+\\-\\s+Antibiotic by Risk'\n",
    "    title = file_name.split(\"Risk\")[0]+str(\"Risk\")\n",
    "    if re.search(pattern=pattern, string=file_name):\n",
    "        file_num=re.findall(r'\\d+', file_name)[-1]\n",
    "        # cleaning for 2017\n",
    "        if file_name.split()[1] == '2017':\n",
    "            if file_num == '1':\n",
    "                type3(path_master,title,file_num)\n",
    "            elif file_num == '2' or file_num == '4':\n",
    "                type5(path_master,title,file_num)\n",
    "            elif file_num == '3' or file_num == '4' or file_num == '8' or file_num == '10':\n",
    "                type1(path_master,title,file_num)\n",
    "            elif file_num == '6' or file_num == '7' or file_num == '9':\n",
    "                type2(path_master,title,file_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out df_ABR\n",
    "import csv\n",
    "\n",
    "# writer = csv.writer(open(path_master+\"/OutputCSV.csv\", 'wb'))\n",
    "df_ABR.to_csv(path_master+\"/df_ABR.csv\")\n",
    "# for row in df_ABR:\n",
    "#     writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To test which function 'type' to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open(path_master+'October 2018 - Antibiotic by Risk10.csv') as fp:\n",
    "    df_ABR1 = pd.read_csv(fp)\n",
    "df_ABR1.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is not to be used yet. To clean df_ABR\n",
    "\n",
    "def convert_1(x):\n",
    "    if re.search(pattern = r'\\w+',string=x):\n",
    "        return x\n",
    "    x=x.strip()\n",
    "    if x[-1]=='%':\n",
    "        return float(x.replace('%,'))\n",
    "    if x=='-':\n",
    "        return 0\n",
    "    if x[0]=='$':\n",
    "        return float(x[1:].replace(',','').replace('-','0'))\n",
    "\n",
    "def ABR_Clean(df):\n",
    "    \"\"\"Cleans fully merged df_ABR columns to ensure appropriate dtypes/formats\"\"\"\n",
    "    for col in df.columns:\n",
    "        df[col]=df[col].apply(convert_1)\n",
    "    \n",
    "# Run this below to convert to .py file before pushing to GitHub\n",
    "get_ipython().system('jupyter nbconvert --to script Antibiotics_by_Risk.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean FULL df_ABR\n",
    "df_ABR = df_final\n",
    "for i in range(len(df_ABR)):\n",
    "    for j in ['Treated','Repulls','Mortalities']:\n",
    "        if df_ABR.iloc[i].loc[j] == '-':\n",
    "            df_ABR.iloc[i].loc[j] = 0\n",
    "        else:\n",
    "            m = df_ABR.iloc[i].loc[j]\n",
    "            m = m.replace(' ','')\n",
    "            df_ABR.iloc[i].loc[j] = m.replace(',','')\n",
    "\n",
    "# Change str -> int for numerical columns\n",
    "# df_ABR['Treated'] = df_ABR['Treated'].apply(lambda x: int(x))\n",
    "# df_ABR['Repulls'] = df_ABR['Repulls'].apply(lambda x: int(x))\n",
    "# df_ABR['Mortalities'] = df_ABR['Mortalities'].apply(lambda x: int(x))\n",
    "\n",
    "df_ABR['Treated'] = df_ABR['Treated'].convert_objects(convert_numeric=True)\n",
    "df_ABR['Repulls'] = df_ABR['Repulls'].convert_objects(convert_numeric=True)\n",
    "df_ABR['Mortalities'] = df_ABR['Mortalities'].convert_objects(convert_numeric=True)\n",
    "\n",
    "# Remove dollar signs from columns\n",
    "df_ABR['Treatment $'] = df_ABR['Treatment $'].apply(lambda x: x[1:])\n",
    "df_ABR['$/Hd/Rx'] = df_ABR['$/Hd/Rx'].apply(lambda x: x[1:])\n",
    "\n",
    "# Remove dashes from columns\n",
    "for i in range(len(df_ABR)):\n",
    "    for j in ['$/Hd/Rx','Treatment $']:\n",
    "        if df_ABR.iloc[i].loc[j] == '-':\n",
    "            df_ABR.iloc[i].loc[j] = 0.0\n",
    "        else:\n",
    "            m = df_ABR.iloc[i].loc[j]\n",
    "            df_ABR.iloc[i].loc[j] = m.replace(',','')\n",
    "            m = m.replace(' ','')\n",
    "            df_ABR.iloc[i].loc[j] = m.replace(',','')\n",
    "\n",
    "# Change str -> float for numerical columns\n",
    "df_ABR['Treatment $'] = df_ABR['Treatment $'].convert_objects(convert_numeric=True)\n",
    "df_ABR['$/Hd/Rx'] = df_ABR['$/Hd/Rx'].convert_objects(convert_numeric=True)\n",
    "\n",
    "# Remove percent signs from columns and convery str -> float\n",
    "df_ABR['Treatment Success(%)'] = df_ABR['Treatment Success(%)'].apply(lambda x: float(x[:-1]))\n",
    "df_ABR['Case Fatality Rate(%)'] = df_ABR['Case Fatality Rate(%)'].apply(lambda x: float(x[:-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
